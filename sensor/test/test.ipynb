{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert keras model to onnx\n",
    "# You may need to reinstall protobuf (and make sure its compatible with your onnx version) https://github.com/onnx/tensorflow-onnx/issues/1557\n",
    "import tensorflow as tf\n",
    "import tf2onnx\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "model = tf.keras.models.load_model(\"models/pretrained-yolov3.h5\")\n",
    "print(model.outputs)\n",
    "\n",
    "spec = (tf.TensorSpec((None, 416, 416, 3), tf.float32, name=\"input\"),)\n",
    "print(spec)\n",
    "model_proto, _ = tf2onnx.convert.from_keras(model, input_signature=spec, output_path=\"models/test1.onnx\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use onnx model for inference\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import onnxruntime as ort\n",
    "import numpy as np\n",
    "\n",
    "IMG_SIZE = 416 # Our dataset image size\n",
    "img_array = cv2.imread(\"white.jpg\")\n",
    "image = cv2.cvtColor(img_array, cv2.COLOR_RGB2BGR)\n",
    "new_array = cv2.resize(image, (IMG_SIZE, IMG_SIZE))\n",
    "print(new_array.shape)\n",
    "# # plt.imshow(new_array)\n",
    "new_array = new_array.reshape(3, IMG_SIZE, IMG_SIZE)\n",
    "print(new_array.shape)\n",
    "\n",
    "# plt.imshow(new_array)\n",
    "# new_array = new_array.astype('float32')\n",
    "# plt.imshow(new_array)\n",
    "# print(new_array.shape)\n",
    "\n",
    "ort_sess = ort.InferenceSession('models/yolov5s416.onnx')\n",
    "outputs = ort_sess.run(None, {'images': [new_array]})\n",
    "# outputs.device_name()\n",
    "\n",
    "# path = __file__.replace(\"./\", \"\")\n",
    "# path = path.replace(\"test.ipynb\", \"\")\n",
    "\n",
    "# with open(\"options.txt\", \"w\") as outfile:\n",
    "#     outfile.write()\n",
    "# print(outputs[0].shape)\n",
    "# print(outputs)\n",
    "print([a.shape for a in outputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from numpy import expand_dims\n",
    "import onnxruntime as ort\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "class BoundBox:\n",
    "\tdef __init__(self, xmin, ymin, xmax, ymax, objness = None, classes = None):\n",
    "\t\tself.xmin = xmin\n",
    "\t\tself.ymin = ymin\n",
    "\t\tself.xmax = xmax\n",
    "\t\tself.ymax = ymax\n",
    "\t\tself.objness = objness\n",
    "\t\tself.classes = classes\n",
    "\t\tself.label = -1\n",
    "\t\tself.score = -1\n",
    "\n",
    "\tdef get_label(self):\n",
    "\t\tif self.label == -1:\n",
    "\t\t\tself.label = np.argmax(self.classes)\n",
    "\t\treturn self.label\n",
    "\n",
    "\tdef get_score(self):\n",
    "\t\tif self.score == -1:\n",
    "\t\t\tself.score = self.classes[self.get_label()]\n",
    "\t\treturn self.score\n",
    "\n",
    "def _sigmoid(x):\n",
    "\treturn 1. / (1. + np.exp(-x))\n",
    "\n",
    "def decode_netout(netout, anchors, obj_thresh, net_h, net_w):\n",
    "\tgrid_h, grid_w = netout.shape[:2]\n",
    "\tnb_box = 3\n",
    "\tnetout = netout.reshape((grid_h, grid_w, nb_box, -1))\n",
    "\tnb_class = netout.shape[-1] - 5\n",
    "\tboxes = []\n",
    "\tnetout[..., :2]  = _sigmoid(netout[..., :2])\n",
    "\tnetout[..., 4:]  = _sigmoid(netout[..., 4:])\n",
    "\tnetout[..., 5:]  = netout[..., 4][..., np.newaxis] * netout[..., 5:]\n",
    "\t# print(netout[..., 5:])\n",
    "\tnetout[..., 5:] *= netout[..., 5:] > obj_thresh\n",
    "\n",
    "\tfor i in range(grid_h*grid_w):\n",
    "\t\trow = i / grid_w\n",
    "\t\tcol = i % grid_w\n",
    "\t\tfor b in range(nb_box):\n",
    "\t\t\t# 4th element is objectness score\n",
    "\t\t\tobjectness = netout[int(row)][int(col)][b][4]\n",
    "\t\t\tif(objectness.all() <= obj_thresh): continue\n",
    "\t\t\t# first 4 elements are x, y, w, and h\n",
    "\t\t\tx, y, w, h = netout[int(row)][int(col)][b][:4]\n",
    "\t\t\tx = (col + x) / grid_w # center position, unit: image width\n",
    "\t\t\ty = (row + y) / grid_h # center position, unit: image height\n",
    "\t\t\tw = anchors[2 * b + 0] * np.exp(w) / net_w # unit: image width\n",
    "\t\t\th = anchors[2 * b + 1] * np.exp(h) / net_h # unit: image height\n",
    "\t\t\t# last elements are class probabilities\n",
    "\t\t\tclasses = netout[int(row)][col][b][5:]\n",
    "\t\t\tbox = BoundBox(x-w/2, y-h/2, x+w/2, y+h/2, objectness, classes)\n",
    "\t\t\tboxes.append(box)\n",
    "\treturn boxes\n",
    "\n",
    "def correct_yolo_boxes(boxes, image_h, image_w, net_h, net_w):\n",
    "\tnew_w, new_h = net_w, net_h\n",
    "\tfor i in range(len(boxes)):\n",
    "\t\tx_offset, x_scale = (net_w - new_w)/2./net_w, float(new_w)/net_w\n",
    "\t\ty_offset, y_scale = (net_h - new_h)/2./net_h, float(new_h)/net_h\n",
    "\t\tboxes[i].xmin = int((boxes[i].xmin - x_offset) / x_scale * image_w)\n",
    "\t\tboxes[i].xmax = int((boxes[i].xmax - x_offset) / x_scale * image_w)\n",
    "\t\tboxes[i].ymin = int((boxes[i].ymin - y_offset) / y_scale * image_h)\n",
    "\t\tboxes[i].ymax = int((boxes[i].ymax - y_offset) / y_scale * image_h)\n",
    "\n",
    "def _interval_overlap(interval_a, interval_b):\n",
    "\tx1, x2 = interval_a\n",
    "\tx3, x4 = interval_b\n",
    "\tif x3 < x1:\n",
    "\t\tif x4 < x1:\n",
    "\t\t\treturn 0\n",
    "\t\telse:\n",
    "\t\t\treturn min(x2,x4) - x1\n",
    "\telse:\n",
    "\t\tif x2 < x3:\n",
    "\t\t\treturn 0\n",
    "\t\telse:\n",
    "\t\t\treturn min(x2,x4) - x3\n",
    "\n",
    "def bbox_iou(box1, box2):\n",
    "\tintersect_w = _interval_overlap([box1.xmin, box1.xmax], [box2.xmin, box2.xmax])\n",
    "\tintersect_h = _interval_overlap([box1.ymin, box1.ymax], [box2.ymin, box2.ymax])\n",
    "\tintersect = intersect_w * intersect_h\n",
    "\tw1, h1 = box1.xmax-box1.xmin, box1.ymax-box1.ymin\n",
    "\tw2, h2 = box2.xmax-box2.xmin, box2.ymax-box2.ymin\n",
    "\tunion = w1*h1 + w2*h2 - intersect\n",
    "\treturn float(intersect) / union\n",
    "\n",
    "def do_nms(boxes, nms_thresh):\n",
    "\tif len(boxes) > 0:\n",
    "\t\tnb_class = len(boxes[0].classes)\n",
    "\telse:\n",
    "\t\treturn\n",
    "\tfor c in range(nb_class):\n",
    "\t\tsorted_indices = np.argsort([-box.classes[c] for box in boxes])\n",
    "\t\tfor i in range(len(sorted_indices)):\n",
    "\t\t\tindex_i = sorted_indices[i]\n",
    "\t\t\tif boxes[index_i].classes[c] == 0: continue\n",
    "\t\t\tfor j in range(i+1, len(sorted_indices)):\n",
    "\t\t\t\tindex_j = sorted_indices[j]\n",
    "\t\t\t\tif bbox_iou(boxes[index_i], boxes[index_j]) >= nms_thresh:\n",
    "\t\t\t\t\tboxes[index_j].classes[c] = 0\n",
    "\n",
    "# # load and prepare an image\n",
    "# def load_image_pixels(filename, shape, size):\n",
    "# \timage = cv2.imread(filename)\n",
    "# \theight, width, _ = image.shape\n",
    "# \timage = cv2.resize(image, (size, size))\n",
    "# \timage = image.reshape(shape)\n",
    "# \treturn image, width, height\n",
    "\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "\n",
    "# load and prepare an image\n",
    "def load_image_pixels(filename, shape):\n",
    "\t# load the image to get its shape\n",
    "\timage = load_img(filename)\n",
    "\twidth, height = image.size\n",
    "\t# load the image with the required size\n",
    "\timage = load_img(filename, target_size=shape)\n",
    "\t# convert to numpy array\n",
    "\timage = img_to_array(image)\n",
    "\t# scale pixel values to [0, 1]\n",
    "\timage = image.astype('float32')\n",
    "\timage /= 255.0\n",
    "\t# add a dimension so that we have one sample\n",
    "\timage = expand_dims(image, 0)\n",
    "\treturn image, width, height\n",
    "\n",
    "# get all of the results above a threshold\n",
    "def get_boxes(boxes, labels, thresh):\n",
    "\tv_boxes, v_labels, v_scores = list(), list(), list()\n",
    "\t# enumerate all boxes\n",
    "\tfor box in boxes:\n",
    "\t\t# enumerate all possible labels\n",
    "\t\tfor i in range(len(labels)):\n",
    "\t\t\t# check if the threshold for this label is high enough\n",
    "\t\t\tif box.classes[i] > thresh:\n",
    "\t\t\t\tv_boxes.append(box)\n",
    "\t\t\t\tv_labels.append(labels[i])\n",
    "\t\t\t\tv_scores.append(box.classes[i]*100)\n",
    "\t\t\t\t# don't break, many labels may trigger for one box\n",
    "\treturn v_boxes, v_labels, v_scores\n",
    " \n",
    "# draw all results\n",
    "def draw_boxes(filename, v_boxes, v_labels, v_scores):\n",
    "\t# load the image\n",
    "\tdata = plt.imread(filename)\n",
    "\t# plot the image\n",
    "\tplt.imshow(data)\n",
    "\t# get the context for drawing boxes\n",
    "\tax = plt.gca()\n",
    "\t# plot each box\n",
    "\tfor i in range(len(v_boxes)):\n",
    "\t\tbox = v_boxes[i]\n",
    "\t\t# get coordinates\n",
    "\t\ty1, x1, y2, x2 = box.ymin, box.xmin, box.ymax, box.xmax\n",
    "\t\t# calculate width and height of the box\n",
    "\t\twidth, height = x2 - x1, y2 - y1\n",
    "\t\t# create the shape\n",
    "\t\trect = Rectangle((x1, y1), width, height, fill=False, color='white')\n",
    "\t\t# draw the box\n",
    "\t\tax.add_patch(rect)\n",
    "\t\t# draw text and score in top left corner\n",
    "\t\tlabel = \"%s (%.3f)\" % (v_labels[i], v_scores[i])\n",
    "\t\tplt.text(x1, y1, label, color='white')\n",
    "\t# show the plot\n",
    "\tplt.show()\n",
    "\n",
    "def run_inference(shape1, shape2, model, input):\n",
    "\t# define the expected input shape for the model\n",
    "\timg_size = 416\n",
    "\t# define our new photo\n",
    "\tphoto_filename = 'bottle.jpg'\n",
    "\t# load and prepare image\n",
    "\t# image, image_w, image_h = load_image_pixels(photo_filename, (img_size, img_size, 3), img_size)\n",
    "\timage, image_w, image_h = load_image_pixels(photo_filename, shape1)\n",
    "\tprint(image.shape)\n",
    "\timage = image.reshape(shape2)\n",
    "\tprint(image.shape)\n",
    "\t# load model from models dir\n",
    "\tort_sess = ort.InferenceSession('models/' + model)\n",
    "\t# run inference\n",
    "\tyhat = ort_sess.run(None, {input: [image]})\n",
    "\t# print shapes of layers\n",
    "\tprint([a.shape for a in yhat])\n",
    "\t# define anchors\n",
    "\tanchors = [[134, 262, 160, 118, 311, 267], [51, 106, 56, 24, 100, 52], [10, 8, 24, 21, 34, 50]]\n",
    "\t# define threshold\n",
    "\tclass_threshold = 0.1\n",
    "\tboxes = list()\n",
    "\tfor i in range(len(yhat)):\n",
    "\t\t# decode the output of the network\n",
    "\t\tboxes += decode_netout(yhat[i][0], anchors[i], class_threshold, img_size, img_size)\n",
    "\t# correct the sizes of the bounding boxes for the shape of the image\n",
    "\t# print(boxes[0].__dict__)\n",
    "\tcorrect_yolo_boxes(boxes, image_h, image_w, img_size, img_size)\n",
    "\t# print(boxes[0].__dict__)\n",
    "\t# suppress non-maximal boxes\n",
    "\tdo_nms(boxes, 0.5)\n",
    "\t# print([a.__dict__ for a in boxes])\n",
    "\t# define labels\n",
    "\tlabels = [\"Clear plastic bottle\", \"Drink carton\", \"Glass bottle\", \"Other plastic bottle\", \"Plastic bottle cap\", \"Rope - strings\"]\n",
    "\t# get the details of the detected objects\n",
    "\tv_boxes, v_labels, v_scores = get_boxes(boxes, labels, class_threshold)\n",
    "\t# summarize what we found\n",
    "\tfor i in range(len(v_boxes)):\n",
    "\t\tprint(v_labels[i], v_scores[i])\n",
    "\t# draw what we found\n",
    "\tdraw_boxes(photo_filename, v_boxes, v_labels, v_scores)\n",
    "\n",
    "\n",
    "run_inference(shape1=(416, 416, 3), shape2=(416, 416, 3), model=\"test1.onnx\", input=\"input\") # test.onnx\n",
    "# run_inference(shape1=(416, 416, 3), shape2=(3, 416, 416), model=\"yolov5s416.onnx\", input=\"images\") # yolov5s416.onnx"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0adcc2737ebf6a4a119f135174df96668767fca1ef1112612db5ecadf2b6d608"
  },
  "kernelspec": {
   "display_name": "Python 3.8.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
